{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected dataset layout (simple + common)\n",
    "data/\n",
    "  train/\n",
    "    images/   (e.g., .png, .jpg)\n",
    "    masks/    (same filenames as images)\n",
    "  val/\n",
    "    images/\n",
    "    masks/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "pip install torch torchvision pillow numpy tqdm opencv-python scipy\n",
    "pip install openslide-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training + inference code (single-file)Loads (image, mask) pairs. Mask is expected to be binary (0 or 255). Applies simple paired augmentations + resize.\n",
    "# Inference + \"cell detections\"urns a binary mask into approximate \"cell detections\" by connected components.\n",
    "#  This is a crude approach: for true cell detection use instance segmentation (e.g., Hover-Net).\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_dir: str = \"data\"\n",
    "    img_size: int = 512\n",
    "    batch_size: int = 4\n",
    "    num_workers: int = 2\n",
    "    lr: float = 1e-4\n",
    "    epochs: int = 25\n",
    "    threshold: float = 0.5\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    out_dir: str = \"runs/unet_cancer\"\n",
    "    save_name: str = \"best_unet.pt\"\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class HistopathSegDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads (image, mask) pairs. Mask is expected to be binary (0 or 255).\n",
    "    Applies simple paired augmentations + resize.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir: str, mask_dir: str, img_size: int, augment: bool = True):\n",
    "        self.img_paths = sorted(glob.glob(os.path.join(img_dir, \"*\")))\n",
    "        self.mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*\")))\n",
    "        assert len(self.img_paths) == len(self.mask_paths), \"Images and masks count mismatch.\"\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def _paired_augment(self, img: np.ndarray, mask: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        # Random flips\n",
    "        if random.random() < 0.5:\n",
    "            img = np.fliplr(img).copy()\n",
    "            mask = np.fliplr(mask).copy()\n",
    "        if random.random() < 0.5:\n",
    "            img = np.flipud(img).copy()\n",
    "            mask = np.flipud(mask).copy()\n",
    "\n",
    "        # Random rotation (0, 90, 180, 270)\n",
    "        k = random.randint(0, 3)\n",
    "        if k:\n",
    "            img = np.rot90(img, k).copy()\n",
    "            mask = np.rot90(mask, k).copy()\n",
    "\n",
    "        # Mild color jitter in HSV (helps stain variability a bit)\n",
    "        if random.random() < 0.3:\n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV).astype(np.float32)\n",
    "            hsv[..., 1] *= random.uniform(0.9, 1.1)  # saturation\n",
    "            hsv[..., 2] *= random.uniform(0.9, 1.1)  # value/brightness\n",
    "            hsv = np.clip(hsv, 0, 255).astype(np.uint8)\n",
    "            img = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        img = np.array(Image.open(self.img_paths[idx]).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(self.mask_paths[idx]).convert(\"L\"))\n",
    "\n",
    "        # Resize\n",
    "        img = cv2.resize(img, (self.img_size, self.img_size), interpolation=cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Binarize mask (0/1)\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "\n",
    "        if self.augment:\n",
    "            img, mask = self._paired_augment(img, mask)\n",
    "\n",
    "        # Normalize to [0,1], CHW\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "\n",
    "        return {\n",
    "            \"image\": torch.tensor(img, dtype=torch.float32),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# U-Net model\n",
    "# -----------------------------\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=1, features=(64, 128, 256, 512)):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Down path\n",
    "        ch = in_ch\n",
    "        for f in features:\n",
    "            self.downs.append(DoubleConv(ch, f))\n",
    "            ch = f\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "\n",
    "        # Up path\n",
    "        rev = list(features)[::-1]\n",
    "        up_ch = features[-1] * 2\n",
    "        for f in rev:\n",
    "            self.ups.append(nn.ConvTranspose2d(up_ch, f, kernel_size=2, stride=2))\n",
    "            self.ups.append(DoubleConv(up_ch, f))\n",
    "            up_ch = f\n",
    "\n",
    "        self.final = nn.Conv2d(features[0], out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skips.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skips = skips[::-1]\n",
    "\n",
    "        for i in range(0, len(self.ups), 2):\n",
    "            x = self.ups[i](x)\n",
    "            skip = skips[i // 2]\n",
    "\n",
    "            # Handle odd sizes (just in case)\n",
    "            if x.shape[-2:] != skip.shape[-2:]:\n",
    "                x = nn.functional.interpolate(x, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "            x = torch.cat([skip, x], dim=1)\n",
    "            x = self.ups[i + 1](x)\n",
    "\n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Losses + metrics\n",
    "# -----------------------------\n",
    "def dice_loss(logits: torch.Tensor, targets: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
    "    probs = torch.sigmoid(logits)\n",
    "    num = 2 * (probs * targets).sum(dim=(2, 3))\n",
    "    den = (probs + targets).sum(dim=(2, 3)) + eps\n",
    "    dice = num / den\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def dice_score(logits: torch.Tensor, targets: torch.Tensor, threshold: float = 0.5, eps: float = 1e-6) -> float:\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = (probs > threshold).float()\n",
    "    num = 2 * (preds * targets).sum(dim=(2, 3))\n",
    "    den = (preds + targets).sum(dim=(2, 3)) + eps\n",
    "    dice = (num / den).mean().item()\n",
    "    return float(dice)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Train / Validate\n",
    "# -----------------------------\n",
    "def run_epoch(model, loader, optimizer, device, train=True) -> Tuple[float, float]:\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    bce = nn.BCEWithLogitsLoss()\n",
    "    total_loss = 0.0\n",
    "    total_dice = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for batch in tqdm(loader, leave=False):\n",
    "        imgs = batch[\"image\"].to(device)\n",
    "        masks = batch[\"mask\"].to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(imgs)\n",
    "            loss = 0.5 * bce(logits, masks) + 0.5 * dice_loss(logits, masks)\n",
    "\n",
    "            if train:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_dice += dice_score(logits, masks)\n",
    "        n += 1\n",
    "\n",
    "    return total_loss / max(n, 1), total_dice / max(n, 1)\n",
    "\n",
    "\n",
    "def train(cfg: Config):\n",
    "    set_seed(cfg.seed)\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "    train_ds = HistopathSegDataset(\n",
    "        img_dir=os.path.join(cfg.data_dir, \"train/images\"),\n",
    "        mask_dir=os.path.join(cfg.data_dir, \"train/masks\"),\n",
    "        img_size=cfg.img_size,\n",
    "        augment=True,\n",
    "    )\n",
    "    val_ds = HistopathSegDataset(\n",
    "        img_dir=os.path.join(cfg.data_dir, \"val/images\"),\n",
    "        mask_dir=os.path.join(cfg.data_dir, \"val/masks\"),\n",
    "        img_size=cfg.img_size,\n",
    "        augment=False,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,\n",
    "                              num_workers=cfg.num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False,\n",
    "                            num_workers=cfg.num_workers, pin_memory=True)\n",
    "\n",
    "    model = UNet().to(cfg.device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "    best_val_dice = -1.0\n",
    "    best_path = os.path.join(cfg.out_dir, cfg.save_name)\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        tr_loss, tr_dice = run_epoch(model, train_loader, optimizer, cfg.device, train=True)\n",
    "        va_loss, va_dice = run_epoch(model, val_loader, optimizer, cfg.device, train=False)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d}/{cfg.epochs} | \"\n",
    "              f\"train loss={tr_loss:.4f} dice={tr_dice:.4f} | \"\n",
    "              f\"val loss={va_loss:.4f} dice={va_dice:.4f}\")\n",
    "\n",
    "        if va_dice > best_val_dice:\n",
    "            best_val_dice = va_dice\n",
    "            torch.save({\"model\": model.state_dict(), \"cfg\": cfg.__dict__}, best_path)\n",
    "            print(f\"  ✓ saved best model to: {best_path} (val dice={best_val_dice:.4f})\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Inference + \"cell detections\"\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def predict_mask(model_path: str, image_path: str, img_size: int = 512, threshold: float = 0.5) -> np.ndarray:\n",
    "    ckpt = torch.load(model_path, map_location=\"cpu\")\n",
    "    model = UNet()\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    model.eval()\n",
    "\n",
    "    img = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "    img_resized = cv2.resize(img, (img_size, img_size), interpolation=cv2.INTER_AREA)\n",
    "    x = (img_resized.astype(np.float32) / 255.0).transpose(2, 0, 1)\n",
    "    x = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    logits = model(x)\n",
    "    prob = torch.sigmoid(logits)[0, 0].numpy()\n",
    "    pred = (prob >= threshold).astype(np.uint8)  # 0/1\n",
    "\n",
    "    return pred  # resized mask\n",
    "\n",
    "\n",
    "def mask_to_cell_detections(binary_mask: np.ndarray, min_area: int = 40) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Turns a binary mask into approximate \"cell detections\" by connected components.\n",
    "    This is a crude approach: for true cell detection use instance segmentation (e.g., Hover-Net).\n",
    "    \"\"\"\n",
    "    labeled, n = ndi.label(binary_mask)\n",
    "    detections = []\n",
    "    for label_id in range(1, n + 1):\n",
    "        ys, xs = np.where(labeled == label_id)\n",
    "        if len(xs) == 0:\n",
    "            continue\n",
    "        area = len(xs)\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        x1, x2 = int(xs.min()), int(xs.max())\n",
    "        y1, y2 = int(ys.min()), int(ys.max())\n",
    "        cx, cy = float(xs.mean()), float(ys.mean())\n",
    "        detections.append({\n",
    "            \"bbox\": [x1, y1, x2, y2],\n",
    "            \"centroid\": [cx, cy],\n",
    "            \"area\": int(area),\n",
    "        })\n",
    "    return detections\n",
    "\n",
    "\n",
    "def overlay_mask(image_path: str, binary_mask: np.ndarray, img_size: int = 512) -> np.ndarray:\n",
    "    img = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "    img = cv2.resize(img, (img_size, img_size), interpolation=cv2.INTER_AREA)\n",
    "    mask_rgb = np.zeros_like(img)\n",
    "    mask_rgb[..., 1] = (binary_mask * 255).astype(np.uint8)  # green overlay channel\n",
    "    out = cv2.addWeighted(img, 0.8, mask_rgb, 0.2, 0)\n",
    "    return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    # 1) Train:\n",
    "    # train(cfg)\n",
    "\n",
    "    # 2) Inference example:\n",
    "    # model_path = os.path.join(cfg.out_dir, cfg.save_name)\n",
    "    # pred = predict_mask(model_path, \"data/val/images/example.png\", img_size=cfg.img_size, threshold=cfg.threshold)\n",
    "    # dets = mask_to_cell_detections(pred, min_area=40)\n",
    "    # print(\"Detections:\", dets[:5], \"… total:\", len(dets))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
